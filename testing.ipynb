{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da11fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# --- Now, a concrete implementation using ASE ---\n",
    "from ase import Atoms\n",
    "from ase.calculators.lj import LennardJones\n",
    "calc = LennardJones(sigma=1, epsilon=1, rc=3, smooth=False)\n",
    "atoms = Atoms('X2')\n",
    "atoms.calc = calc\n",
    "\n",
    "print(atoms.get_potential_energy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8875c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "###############################\n",
    "# Base Potential Class (Abstract)\n",
    "###############################\n",
    "\n",
    "class PotentialEnergySurface(ABC):\n",
    "    \"\"\"Abstract base class for potential energy surfaces.\"\"\"\n",
    "\n",
    "    def __init__(self): \n",
    "        self.max_acceptable_force_mag = np.inf # will be updated by ABC later\n",
    "        self.energy_calls = 0 \n",
    "        self.force_calls = 0\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _potential(self, position: np.ndarray) -> float: \n",
    "        \"\"\"Compute potential energy at given position.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def potential(self, position: np.ndarray) -> float: \n",
    "        \"\"\"\n",
    "        Wrapper for potential calls. \n",
    "        \n",
    "        DO NOT EDIT: Users should implement _potential()\n",
    "        \"\"\"\n",
    "        self.energy_calls += 1\n",
    "        return self._potential(position)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def default_starting_position(self) -> np.ndarray:\n",
    "        \"\"\"Return default starting position for this PES.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _gradient(self, position) -> np.ndarray:\n",
    "        \"\"\"Compute analytic gradient at given position, if available\n",
    "        Raise NotImplementedError if not implemented.\n",
    "        \n",
    "        If your potential has no analytical gradient, simply omit this method \n",
    "        from your implementation, and the ABC will perform finite-difference.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Analytic gradient not implemented for this PES.\")\n",
    "    \n",
    "    def gradient(self, position) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Wrapper for _gradient with built-in force magnitude limiting\n",
    "        DO NOT EDIT: Users should implement _gradient() for analytical gradient calculation\n",
    "        \"\"\"\n",
    "        if (norm := np.linalg.norm(grad := self._gradient(position))) > self.max_acceptable_force_mag: \n",
    "            print(f\"Warning: Gradient value of {grad} detected as likely unphysically large in magnitude; shrunk to magnitude {self.max_acceptable_force_mag}\")\n",
    "            grad = self.max_acceptable_force_mag * grad / norm\n",
    "        \n",
    "        self.force_calls += 1\n",
    "        return grad       \n",
    "\n",
    "    def plot_range(self) -> tuple:\n",
    "        \"\"\"Return plotting range for visualization.\"\"\"\n",
    "        return None\n",
    "        \n",
    "    def known_minima(self) -> list[np.ndarray]:\n",
    "        \"\"\"Return known basins (for analysis).\"\"\"\n",
    "        return None \n",
    "\n",
    "    def known_saddles(self) -> list[np.ndarray]:\n",
    "        \"\"\"Return known saddles (for analysis).\"\"\"\n",
    "        return None\n",
    "\n",
    "\n",
    "###############################\n",
    "# Concrete Potential Implementations\n",
    "###############################\n",
    "\n",
    "class DoubleWell1D(PotentialEnergySurface):\n",
    "    \"\"\"1D double well potential.\"\"\"\n",
    "    \n",
    "    def _potential(self, x):\n",
    "        \"\"\"Compute double well potential with minima at x=-1 and x=1.\"\"\"\n",
    "        return 1/6 * (5 * (x**2 - 1))**2\n",
    "    \n",
    "    def _gradient(self, x):\n",
    "        return np.array([50/3 * x * (x**2-1)])\n",
    "        \n",
    "    def default_starting_position(self):\n",
    "        return np.array([-1.0], dtype=float)\n",
    "        \n",
    "    def plot_range(self):\n",
    "        return (-2, 2)\n",
    "        \n",
    "    def known_minima(self):\n",
    "        return [np.array([-1.0], dtype=float), np.array([1.0], dtype=float)]\n",
    "    \n",
    "    def known_saddles(self):\n",
    "        return [np.array([0.0], dtype=float)]\n",
    "\n",
    "class Complex1D(PotentialEnergySurface):\n",
    "    \n",
    "    def _potential(self, x):\n",
    "        a=[6.5, 4.2, -7.3, -125]\n",
    "        b=[2.5, 4.3, 1.5, 0.036]\n",
    "        c=[9.7, 1.9, -2.5, 12]\n",
    "        V = x**2\n",
    "        for i in range(4):\n",
    "            exponent = -b[i]*(x-c[i])**2\n",
    "            exponent = np.clip(exponent, -100, 100)\n",
    "            V += a[i]*np.exp(exponent)\n",
    "        return V\n",
    "     \n",
    "    def default_starting_position(self):\n",
    "        return np.array([0.0], dtype=float)\n",
    "        \n",
    "    def plot_range(self):\n",
    "        return (-3.5, 11.6)\n",
    "        \n",
    "    def known_minima(self):\n",
    "        return [\n",
    "                np.array([-2.27151]), \n",
    "                np.array([0.41295]), \n",
    "                np.array([2.71638]), \n",
    "                np.array([8.69999]), \n",
    "                np.array([10.35518]) \n",
    "                ]\n",
    "    \n",
    "    def known_saddles(self):\n",
    "        return [\n",
    "                np.array([-1.2645]),\n",
    "                np.array([1.94219]), \n",
    "                np.array([4.55508]),\n",
    "                np.array([9.7913])\n",
    "                ]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class StandardMullerBrown2D(PotentialEnergySurface):\n",
    "    \"\"\"2D Muller-Brown potential.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.A = np.array([-200, -100, -170, 15])\n",
    "        self.a = np.array([-1, -1, -6.5, 0.7])\n",
    "        self.b = np.array([0, 0, 11, 0.6])\n",
    "        self.c = np.array([-10, -10, -6.5, 0.7])\n",
    "        self.x0 = np.array([1, 0, -0.5, -1])\n",
    "        self.y0 = np.array([0, 0.5, 1.5, 1])\n",
    "\n",
    "    def _potential(self, pos):\n",
    "        \"\"\"Compute the Muller-Brown potential with numerical safeguards.\"\"\"\n",
    "        x, y = pos[0], pos[1]\n",
    "\n",
    "        V = 0.0\n",
    "        for i in range(4):\n",
    "            dx = x - self.x0[i]\n",
    "            dy = y - self.y0[i]\n",
    "            exponent = self.a[i]*dx**2 + self.b[i]*dx*dy + self.c[i]*dy**2\n",
    "            exponent = np.clip(exponent, -100, 100)\n",
    "            V += self.A[i] * np.exp(exponent)\n",
    "        return V\n",
    "\n",
    "    def _gradient(self, position):\n",
    "        x, y = position[0], position[1]\n",
    "\n",
    "        dVdx = 0.0\n",
    "        dVdy = 0.0\n",
    "\n",
    "        for i in range(4):\n",
    "            dx = x - self.x0[i]\n",
    "            dy = y - self.y0[i]\n",
    "            exponent = self.a[i]*dx**2 + self.b[i]*dx*dy + self.c[i]*dy**2\n",
    "            exp_term = np.exp(np.clip(exponent, -100, 100))\n",
    "            dVdx += self.A[i] * exp_term * (2*self.a[i]*dx + self.b[i]*dy)\n",
    "            dVdy += self.A[i] * exp_term * (self.b[i]*dx + 2*self.c[i]*dy)\n",
    "        \n",
    "        grad = np.array([dVdx, dVdy])            \n",
    "        return grad \n",
    "\n",
    "    def default_starting_position(self):\n",
    "        return np.array([0.0, 0.0], dtype=float)\n",
    "\n",
    "    def plot_range(self):\n",
    "        return ((-2, 2), (-1, 2))\n",
    "\n",
    "    def known_minima(self):\n",
    "        return [\n",
    "            np.array([-0.5582236346, 1.441725842]),  # Basin A\n",
    "            np.array([0.6234994049, 0.02803775853]), # Basin B  \n",
    "            np.array([-0.050010823, 0.4666941049])   # Basin C\n",
    "        ]\n",
    "\n",
    "    def known_saddles(self):\n",
    "        return [\n",
    "            np.array([0.212486582, 0.2929883251]),   # Transition A<-->B\n",
    "            np.array([-0.8220015587, 0.6243128028])  # Transition B<-->C\n",
    "        ]\n",
    "    \n",
    "\n",
    "# --- Now, a concrete implementation using ASE ---\n",
    "from ase import Atoms\n",
    "from ase.calculators.lj import LennardJones\n",
    "\n",
    "class ASEPotentialEnergySurface(PotentialEnergySurface):\n",
    "    \"\"\"\n",
    "    A base class for PES implementations that use ASE calculators.\n",
    "    \"\"\"\n",
    "    def __init__(self, ase_atoms, calculator):\n",
    "        super().__init__()\n",
    "        self.atoms = ase_atoms\n",
    "        if calculator is not None: \n",
    "            self.atoms.calc = calculator\n",
    "\n",
    "    def _potential(self, position):\n",
    "        \"\"\"Compute potential energy at given position using ASE.\"\"\"\n",
    "        # Ensure 'position' is a numpy array of correct shape for ASE\n",
    "        # For N atoms, it should be (N, 3)\n",
    "        self.atoms.positions = position.reshape(-1, 3)\n",
    "        return self.atoms.get_potential_energy()\n",
    "\n",
    "    def _gradient(self, position):\n",
    "        \"\"\"Compute gradient at given position using ASE.\"\"\"\n",
    "        self.atoms.positions = position.reshape(-1, 3)\n",
    "        # ASE returns forces, which are negative gradients\n",
    "        forces = self.atoms.get_forces()\n",
    "        return -forces.flatten() # Flatten to match your 'position' input shape\n",
    "\n",
    "\n",
    "from ase import Atoms\n",
    "from ase.calculators.lj import LennardJones\n",
    "import numpy as np\n",
    "\n",
    "class LennardJonesCluster(ASEPotentialEnergySurface):\n",
    "    def __init__(self, num_atoms, initial_positions=None, \n",
    "                 sigma=1.0, epsilon=1.0, min_distance=0.9, padding=0.5):\n",
    "        \"\"\"\n",
    "        A smarter LJ cluster implementation that:\n",
    "        - Automatically scales the box size with num_atoms^(1/3)\n",
    "        - Ensures particles aren't too close (avoids huge repulsive forces)\n",
    "        - Can generate reasonable random or lattice initial positions\n",
    "        \n",
    "        Args:\n",
    "            num_atoms: Number of LJ particles\n",
    "            initial_positions: Optional starting positions (None for auto-generated)\n",
    "            sigma: LJ σ parameter\n",
    "            epsilon: LJ ε parameter\n",
    "            min_distance: Minimum allowed distance between particles (in units of σ)\n",
    "            padding: Extra space around cluster (in units of σ)\n",
    "        \"\"\"\n",
    "        self.num_atoms = num_atoms\n",
    "        self.sigma = sigma\n",
    "        self.epsilon = epsilon\n",
    "        self.min_distance = min_distance * sigma\n",
    "        self.padding = padding * sigma\n",
    "\n",
    "        # Calculate reasonable box size\n",
    "        self.box_size = self._calculate_box_size(num_atoms)\n",
    "        \n",
    "        # Generate initial positions if not provided\n",
    "        if initial_positions is None:\n",
    "            initial_positions = self.default_starting_position()\n",
    "        \n",
    "        # Create ASE Atoms object\n",
    "        atoms = Atoms(symbols=['X']*num_atoms, \n",
    "                     positions=initial_positions.reshape(-1,3),\n",
    "                     pbc=False)\n",
    "        \n",
    "        # Setup LJ calculator\n",
    "        calculator = LennardJones(sigma=sigma, epsilon=epsilon, \n",
    "                                rc=3*sigma, smooth=False)\n",
    "        \n",
    "        atoms.calc = calculator\n",
    "\n",
    "        super().__init__(atoms, None)\n",
    "\n",
    "    def _calculate_box_size(self, num_atoms):\n",
    "        \"\"\"Calculate box size based on particle count and LJ parameters\"\"\"\n",
    "        # Volume scales with number of particles\n",
    "        volume_per_atom = (4/3) * np.pi * (self.min_distance/2)**3\n",
    "        total_volume = num_atoms * volume_per_atom\n",
    "        \n",
    "        # Cubic root to get linear dimension\n",
    "        linear_size = total_volume ** (1/3)\n",
    "        \n",
    "        # Add padding and convert to box length\n",
    "        return linear_size + 2*self.padding\n",
    "\n",
    "    def default_starting_position(self):\n",
    "        \"\"\"Generate initial positions that avoid extreme forces\"\"\"\n",
    "        positions = np.zeros((self.num_atoms, 3))\n",
    "        \n",
    "        # First particle at origin\n",
    "        positions[0] = [0, 0, 0]\n",
    "        \n",
    "        # Place subsequent particles with reasonable spacing\n",
    "        for i in range(1, self.num_atoms):\n",
    "            while True:\n",
    "                # Random position in sphere of decreasing radius\n",
    "                r = self.min_distance * (1 + 0.5*i)\n",
    "                pos = np.random.uniform(-r, r, size=3)\n",
    "                \n",
    "                # Check distances to existing particles\n",
    "                valid = True\n",
    "                for j in range(i):\n",
    "                    if np.linalg.norm(pos - positions[j]) < self.min_distance:\n",
    "                        valid = False\n",
    "                        break\n",
    "                \n",
    "                if valid:\n",
    "                    positions[i] = pos\n",
    "                    break\n",
    "        \n",
    "        # Center the cluster\n",
    "        positions -= np.mean(positions, axis=0)\n",
    "        \n",
    "        return positions.flatten()\n",
    "\n",
    "    def known_minima(self):\n",
    "        \"\"\"Return known minima for small clusters\"\"\"\n",
    "        if self.num_atoms == 2:\n",
    "            return [np.array([0,0,0, 0,0,1.12*self.sigma])]  # Diatomic minimum\n",
    "        elif self.num_atoms == 3:\n",
    "            return [np.array([0,0,0, 0,0.5*1.12*self.sigma,0.866*1.12*self.sigma, \n",
    "                            0,-0.5*1.12*self.sigma,0.866*1.12*self.sigma])]  # Equilateral triangle\n",
    "        # Add more known minima as needed\n",
    "        return []\n",
    "\n",
    "    def known_saddles(self):\n",
    "        \"\"\"Return known transition states for small clusters\"\"\"\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b596313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.97071992,  1.01644186, -0.09019999,  0.97071992, -1.01644186,\n",
       "        0.09019999])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypot = LennardJonesCluster(2)\n",
    "mypot.gradient(mypot.default_starting_position())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3c81e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.170010845239571), np.float64(1.2883825695124027), np.float64(1.3662558418380324), np.float64(1.3620670608578265), np.float64(1.3603765226308688)]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "ms = [array([ 0.45580241,  0.29975277,  0.52179542, -0.21605851, -0.59245761,\n",
    "        0.63352984]), array([ 0.36166507,  0.08112468,  0.6680567 ,  0.33412726, -0.95378262,\n",
    "        0.23431761]), array([ 0.65501316,  0.21041675,  0.64708384,  0.44878615, -0.83184561,\n",
    "        0.28503325]), array([ 0.6648861 ,  0.25209209,  0.5170549 ,  0.35601014, -0.82702809,\n",
    "        0.52109335]), array([ 0.66592189,  0.25642632,  0.52230116,  0.35517685, -0.82214786,\n",
    "        0.51627673])]\n",
    "\n",
    "print([np.linalg.norm(arr) for arr in ms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45efcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class Optimizer(ABC):\n",
    "    \"\"\"Abstract base class for all optimizer backends\"\"\"\n",
    "    \n",
    "    def __init__(self, abc_sim):\n",
    "        self.abc_sim = abc_sim\n",
    "        self._reset_state()\n",
    "\n",
    "    def _reset_state(self):\n",
    "        \"\"\"Initialize/clear all trajectory tracking\"\"\"\n",
    "        \n",
    "        self.trajectory = []\n",
    "        self.unbiased_energies = []\n",
    "        self.biased_energies = []\n",
    "        self.unbiased_forces = []\n",
    "        self.biased_forces = []\n",
    "        self._last_x = None\n",
    "\n",
    "    def _compute(self, x):\n",
    "        \"\"\"Compute and record energy/forces (cached)\"\"\"\n",
    "        if self._last_x is None or not np.allclose(x, self._last_x):\n",
    "            self._last_x = x.copy()\n",
    "            \n",
    "            # Your existing computation logic\n",
    "            unbiased_energy = self.abc_sim.potential.potential(x)\n",
    "            biased_energy = self.abc_sim.compute_biased_potential(x, deepcopy(unbiased_energy)) # reuse unbiased call from before\n",
    "\n",
    "            try:\n",
    "                unbiased_force = - self.abc_sim.potential.gradient(x)\n",
    "            except NotImplementedError:\n",
    "                unbiased_force = None\n",
    "            biased_force = self.abc_sim.compute_biased_force(x, unbiased_force)\n",
    "           \n",
    "            # Record\n",
    "            self.trajectory.append(x.copy())\n",
    "            self.unbiased_energies.append(unbiased_energy)\n",
    "            self.biased_energies.append(biased_energy)\n",
    "            self.unbiased_forces.append(unbiased_force)\n",
    "            self.biased_forces.append(biased_force)\n",
    "        \n",
    "        return self.biased_energies[-1], -self.biased_forces[-1]  # (energy, -gradient)\n",
    "\n",
    "\n",
    "    def get_traj_data(self):\n",
    "        accepted = self._accepted_steps()\n",
    "        indices = []\n",
    "        for pos in accepted:\n",
    "            found = False\n",
    "            for i, traj_pos in enumerate(self.trajectory):\n",
    "                if np.allclose(pos, traj_pos, atol=1e-10):\n",
    "                    indices.append(i)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                # Try with a higher tolerance\n",
    "                for i, traj_pos in enumerate(self.trajectory):\n",
    "                    if np.allclose(pos, traj_pos, atol=1e-8):\n",
    "                        indices.append(i)\n",
    "                        found = True\n",
    "                        print(f\"Warning: Position {pos} not found with tol={1e-10}, matched with tol={1e-8} at index {i}.\")\n",
    "                        break\n",
    "            if not found:\n",
    "                print(f\"Warning: Accepted position {pos} not found in trajectory with any tolerance.\")\n",
    "        traj = [self.trajectory[i] for i in indices]\n",
    "        unbiased_e = [self.unbiased_energies[i] for i in indices]\n",
    "        biased_e = [self.biased_energies[i] for i in indices]\n",
    "        unbiased_f = [self.unbiased_forces[i] for i in indices]\n",
    "        biased_f = [self.biased_forces[i] for i in indices]\n",
    "        return (traj, unbiased_e, biased_e, unbiased_f, biased_f)\n",
    "\n",
    "    def descend(self, x0, max_steps=None, convergence_threshold=None):\n",
    "        \"\"\"Universal descent method (same for all backends)\"\"\"\n",
    "        self._reset_state()\n",
    "        result = self._run_optimization(x0, max_steps, convergence_threshold)\n",
    "        return result, self.get_traj_data()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _run_optimization(self, x0, max_steps, convergence_threshold):\n",
    "        \"\"\"\n",
    "        Backend-specific optimization (implemented by child classes)\n",
    "        Should call _compute()\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _accepted_steps():\n",
    "        \"\"\"\n",
    "        Return a list of the positions that were actually accepted by the optimizer, in the order they were accepted\n",
    "        \n",
    "        Would be nicer if could get the indices, but many optimizer types (e.g. SciPy) do not allow for this\n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ScipyOptimizer(Optimizer):\n",
    "    def __init__(self, abc_sim, method='BFGS', **kwargs):\n",
    "        \"\"\"\n",
    "        SciPy optimizer supporting BFGS, L-BFGS-B, and CG methods.\n",
    "        \n",
    "        Args:\n",
    "            method: One of 'BFGS', 'L-BFGS-B', or 'CG'\n",
    "            kwargs: Method-specific options\n",
    "        \"\"\"\n",
    "        super().__init__(abc_sim)\n",
    "        if method not in ['BFGS', 'L-BFGS-B', 'CG']:\n",
    "            raise ValueError(f\"Method '{method}' not supported. Choose from: BFGS, L-BFGS-B, CG\")\n",
    "        self.method = method\n",
    "        self.optimizer_kwargs = kwargs\n",
    "        self._result = None\n",
    "        self.accepted_steps = []\n",
    "\n",
    "    def _run_optimization(self, x0, max_steps=None, convergence_threshold=None):\n",
    "        self._reset_state()\n",
    "        self.accepted_steps = [x0.copy()]\n",
    "        last_accepted_x = x0.copy()\n",
    "        \n",
    "        options = self.optimizer_kwargs.copy()\n",
    "        if max_steps is not None:\n",
    "            options['maxiter'] = max_steps\n",
    "            # Some methods use different names for max iterations\n",
    "            options['maxfun'] = max_steps * 5  # For methods that count function evaluations\n",
    "            options['maxls'] = max_steps  # For line search steps\n",
    "\n",
    "        def callback(x):\n",
    "            nonlocal last_accepted_x\n",
    "            if not np.allclose(x, last_accepted_x):\n",
    "                self._compute(x)  # Ensure cached\n",
    "                self.accepted_steps.append(x.copy())\n",
    "                last_accepted_x = x.copy()\n",
    "\n",
    "        self._result = minimize(\n",
    "            fun=lambda x: self._compute(x)[0],\n",
    "            x0=x0,\n",
    "            method=self.method,\n",
    "            jac=lambda x: self._compute(x)[1],\n",
    "            tol=convergence_threshold,\n",
    "            callback=callback,\n",
    "            options=options\n",
    "        )\n",
    "\n",
    "        return self._package_result()\n",
    "    \n",
    "    def _construct_l_bfgs_hess_inv(self, hess_inv_operator: LinearOperator):\n",
    "        \"\"\"Convert L-BFGS-B LinearOperator inverse Hessian to dense matrix\"\"\"\n",
    "        n = self.abc_sim.dimension\n",
    "        I = np.eye(n)\n",
    "        \n",
    "        # Apply the LinearOperator to each basis vector\n",
    "        inv_H = np.column_stack([hess_inv_operator.matvec(I[:, i]) for i in range(n)])\n",
    "        \n",
    "        # Symmetrize the result\n",
    "        inv_H = 0.5 * (inv_H + inv_H.T)\n",
    "        \n",
    "        return inv_H\n",
    "\n",
    "    def _package_result(self):\n",
    "        \"\"\"Standardized result format\"\"\"\n",
    "        result = {\n",
    "            'x': self._result.x,\n",
    "            'converged': self._result.success,\n",
    "            'nit': self._result.nit,\n",
    "            'message': self._result.message\n",
    "        }\n",
    "        \n",
    "        # Handle Hessian information differently for each method\n",
    "        if hasattr(self._result, 'hess_inv'):\n",
    "            if self.method == 'BFGS':\n",
    "                # BFGS provides dense matrix directly\n",
    "                result['hess_inv'] = self._result.hess_inv\n",
    "            elif self.method == 'L-BFGS-B':\n",
    "                # L-BFGS-B needs conversion from LinearOperator\n",
    "                result['hess_inv'] = self._construct_l_bfgs_hess_inv(self._result.hess_inv)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _accepted_steps(self):\n",
    "        return self.accepted_steps.copy()\n",
    "\n",
    "    @property \n",
    "    def inv_hessian(self):\n",
    "        \"\"\"Get inverse Hessian approximation if available\"\"\"\n",
    "        if not hasattr(self, '_result'):\n",
    "            raise AttributeError(\"Optimization not yet run\")\n",
    "        \n",
    "        if self.method == 'BFGS' and hasattr(self._result, 'hess_inv'):\n",
    "            return self._result.hess_inv\n",
    "        elif self.method == 'L-BFGS-B' and hasattr(self._result, 'hess_inv'):\n",
    "            return self._construct_l_bfgs_hess_inv(self._result.hess_inv)\n",
    "        \n",
    "        raise AttributeError(f\"Inverse Hessian not available for method '{self.method}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4b51bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60159/2599499563.py:139: OptimizeWarning: Unknown solver options: maxfun, maxls\n",
      "  self._result = minimize(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'x': array([2.55226954]),\n",
       "  'converged': False,\n",
       "  'nit': 2,\n",
       "  'message': 'Maximum number of iterations has been exceeded.',\n",
       "  'hess_inv': array([[0.28664761]])},\n",
       " ([array([18.]), array([12.95]), array([2.55226954])],\n",
       "  [array([289.79698708]), array([46.69848374]), array([2.1604557])],\n",
       "  [array([289.79698708]), array([46.69848374]), array([2.1604557])],\n",
       "  [None, None, None],\n",
       "  [array([-50.77570158]), array([-34.17667471]), array([2.09688938])]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ca_abc import CurvatureAdaptiveABC\n",
    "from potentials import *\n",
    "mypot = Complex1D()\n",
    "myabc = CurvatureAdaptiveABC(mypot)\n",
    "\n",
    "myopt = ScipyOptimizer(myabc)\n",
    "\n",
    "\n",
    "result = myopt.descend([18], 2, 1e-5)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
